{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0b5129",
   "metadata": {},
   "source": [
    "# Dead Tree Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "211a0ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Path to dataset files: /Users/evanchan19/.cache/kagglehub/datasets/meteahishali/aerial-imagery-for-standing-dead-tree-segmentation/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"meteahishali/aerial-imagery-for-standing-dead-tree-segmentation\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "053690de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All masks valid: grayscale + binary (0/255)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Relative path\n",
    "dataset_dir = \"data/USA_segmentation\"\n",
    "rgb_dir = os.path.join(dataset_dir, \"RGB_images\")\n",
    "nrg_dir = os.path.join(dataset_dir, \"NRG_images\")\n",
    "mask_dir = os.path.join(dataset_dir, \"masks\")\n",
    "\n",
    "# create train/val \n",
    "for split in [\"train\", \"val\"]:\n",
    "    for subfolder in [\"RGB_images\", \"NRG_images\", \"masks\"]:\n",
    "        os.makedirs(os.path.join(dataset_dir, split, subfolder), exist_ok=True)\n",
    "\n",
    "def build_core_map(directory, prefix):\n",
    "    return {\n",
    "        f[len(prefix):]: f\n",
    "        for f in os.listdir(directory)\n",
    "        if f.startswith(prefix) and f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    }\n",
    "\n",
    "rgb_map = build_core_map(rgb_dir, \"RGB_\")\n",
    "nrg_map = build_core_map(nrg_dir, \"NRG_\")\n",
    "mask_map = build_core_map(mask_dir, \"mask_\")\n",
    "\n",
    "\n",
    "matched_core_names = sorted(list(set(rgb_map) & set(nrg_map) & set(mask_map)))\n",
    "random.seed(42)\n",
    "random.shuffle(matched_core_names)\n",
    "\n",
    "# 80 20 Train Test set \n",
    "split_index = int(len(matched_core_names) * 0.8)\n",
    "train_cores = matched_core_names[:split_index]\n",
    "val_cores = matched_core_names[split_index:]\n",
    "\n",
    "# Copy to its direcotry \n",
    "def copy_from_map(core_list, split):\n",
    "    for core in core_list:\n",
    "        shutil.copy(os.path.join(rgb_dir, rgb_map[core]), os.path.join(dataset_dir, split, \"RGB_images\", rgb_map[core]))\n",
    "        shutil.copy(os.path.join(nrg_dir, nrg_map[core]), os.path.join(dataset_dir, split, \"NRG_images\", nrg_map[core]))\n",
    "        shutil.copy(os.path.join(mask_dir, mask_map[core]), os.path.join(dataset_dir, split, \"masks\", mask_map[core]))\n",
    "\n",
    "copy_from_map(train_cores, \"train\")\n",
    "copy_from_map(val_cores, \"val\")\n",
    "\n",
    "\n",
    "invalid_masks = []\n",
    "def validate_masks(mask_folder):\n",
    "    for fname in os.listdir(mask_folder):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(mask_folder, fname)).convert(\"L\")\n",
    "            arr = np.array(img)\n",
    "            if arr.ndim != 2 or not np.isin(arr, [0, 255]).all():\n",
    "                invalid_masks.append(os.path.join(mask_folder, fname))\n",
    "        except Exception:\n",
    "            invalid_masks.append(os.path.join(mask_folder, fname))\n",
    "\n",
    "validate_masks(os.path.join(dataset_dir, \"train\", \"masks\"))\n",
    "validate_masks(os.path.join(dataset_dir, \"val\", \"masks\"))\n",
    "\n",
    "\n",
    "if invalid_masks:\n",
    "    print(\"\\n‚ùå Invalid mask files (non-binary or wrong format):\")\n",
    "    for f in invalid_masks:\n",
    "        print(\" -\", f)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All masks valid: grayscale + binary (0/255)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab634f05",
   "metadata": {},
   "source": [
    "## 2.   Image analysis before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12ce6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scanned 355 images in: /Users/evanchan19/Desktop/COMP9517/project/data/USA_segmentation/train/RGB_images\n",
      "- Average size: 395.6 x 385.1\n",
      "- Min size: 317 x 297\n",
      "- Max size: 630 x 636\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def analyze_image_sizes(image_dir):\n",
    "    heights, widths = [], []\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(image_dir)\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "\n",
    "    for fname in image_files:\n",
    "        path = os.path.join(image_dir, fname)\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Failed to load: {fname}\")\n",
    "            continue\n",
    "        h, w = img.shape[:2]\n",
    "        heights.append(h)\n",
    "        widths.append(w)\n",
    "\n",
    "    heights = np.array(heights)\n",
    "    widths = np.array(widths)\n",
    "\n",
    "    print(f\"‚úÖ Scanned {len(heights)} images in: {image_dir}\")\n",
    "    print(f\"- Average size: {np.mean(widths):.1f} x {np.mean(heights):.1f}\")\n",
    "    print(f\"- Min size: {np.min(widths)} x {np.min(heights)}\")\n",
    "    print(f\"- Max size: {np.max(widths)} x {np.max(heights)}\")\n",
    "\n",
    "\n",
    "# ÊõøÊç¢‰∏∫‰Ω†Ë¶ÅÂàÜÊûêÁöÑÁõÆÂΩïÔºàRGB Êàñ NRGÔºâ\n",
    "image_dir = \"/Users/evanchan19/Desktop/COMP9517/project/data/USA_segmentation/train/RGB_images\"\n",
    "analyze_image_sizes(image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ca607fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Total checked: 355\n",
      "‚úÖ Matched sizes: 355\n",
      "üéâ No size mismatches found between RGB and NRG pairs.\n",
      "\n",
      "üìê NRG image size summary:\n",
      "- Average size: 395.6 x 385.1\n",
      "- Min size: 317 x 297\n",
      "- Max size: 630 x 636\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def analyze_rgb_nir_pair_sizes(rgb_dir, nrg_dir):\n",
    "    mismatched = []\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    nir_heights, nir_widths = [], []\n",
    "\n",
    "    core_names = [\n",
    "        f.replace(\"RGB_\", \"\")\n",
    "        for f in os.listdir(rgb_dir)\n",
    "        if f.startswith(\"RGB_\") and f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ]\n",
    "\n",
    "    for core in sorted(core_names):\n",
    "        rgb_path = os.path.join(rgb_dir, f\"RGB_{core}\")\n",
    "        nrg_path = os.path.join(nrg_dir, f\"NRG_{core}\")\n",
    "\n",
    "        if not os.path.exists(nrg_path):\n",
    "            print(f\"‚ùå NRG image missing: {nrg_path}\")\n",
    "            continue\n",
    "\n",
    "        rgb_img = cv2.imread(rgb_path)\n",
    "        nrg_img = cv2.imread(nrg_path)\n",
    "\n",
    "        if rgb_img is None or nrg_img is None:\n",
    "            print(f\"‚ö†Ô∏è Failed to load: {core}\")\n",
    "            continue\n",
    "\n",
    "        total += 1\n",
    "        if rgb_img.shape[:2] != nrg_img.shape[:2]:\n",
    "            mismatched.append(core)\n",
    "            print(f\"‚ùó Size mismatch in: {core}\")\n",
    "        else:\n",
    "            matched += 1\n",
    "            h, w = nrg_img.shape[:2]\n",
    "            nir_heights.append(h)\n",
    "            nir_widths.append(w)\n",
    "\n",
    "    print(f\"\\n‚úÖ Total checked: {total}\")\n",
    "    print(f\"‚úÖ Matched sizes: {matched}\")\n",
    "    if mismatched:\n",
    "        print(f\"‚ùå Mismatched sizes ({len(mismatched)}):\")\n",
    "        for name in mismatched:\n",
    "            print(f\" - {name}\")\n",
    "    else:\n",
    "        print(\"üéâ No size mismatches found between RGB and NRG pairs.\")\n",
    "\n",
    "    # ÊâìÂç∞ NIR ÂõæÂÉèÂ∞∫ÂØ∏ÁªüËÆ°‰ø°ÊÅØ\n",
    "    if nir_heights and nir_widths:\n",
    "        nir_heights = np.array(nir_heights)\n",
    "        nir_widths = np.array(nir_widths)\n",
    "        print(f\"\\nüìê NRG image size summary:\")\n",
    "        print(f\"- Average size: {np.mean(nir_widths):.1f} x {np.mean(nir_heights):.1f}\")\n",
    "        print(f\"- Min size: {np.min(nir_widths)} x {np.min(nir_heights)}\")\n",
    "        print(f\"- Max size: {np.max(nir_widths)} x {np.max(nir_heights)}\")\n",
    "\n",
    "# Áî®‰Ω†ÁöÑË∑ØÂæÑÊõøÊç¢‰ª•‰∏ãÁõÆÂΩï\n",
    "rgb_dir = \"/Users/evanchan19/Desktop/COMP9517/project/data/USA_segmentation/train/RGB_images\"\n",
    "nrg_dir = \"/Users/evanchan19/Desktop/COMP9517/project/data/USA_segmentation/train/NRG_images\"\n",
    "analyze_rgb_nir_pair_sizes(rgb_dir, nrg_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c42a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for conv1/kernel:0 and backbone identity...\n",
      "‚ùå conv1/kernel:0 not found. Possibly excluded during save or replaced.\n",
      "‚úÖ Detected backbone: resnet101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 'resnet101')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def inspect_maskrcnn_weights(h5_path):\n",
    "    \"\"\"\n",
    "    Inspect a Mask R-CNN .h5 weight file to detect:\n",
    "    - The number of input channels in the first convolutional layer\n",
    "    - The backbone type: resnet50 or resnet101\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            conv1_found = False\n",
    "            input_channels = None\n",
    "            backbone_type = None\n",
    "\n",
    "            print(\"üîç Searching for conv1/kernel:0 and backbone identity...\")\n",
    "\n",
    "            for top_key in f.keys():\n",
    "                # Optional: print all top keys for debugging\n",
    "                # print(f\"- {top_key}\")\n",
    "\n",
    "                # Check conv1\n",
    "                if \"conv1\" in top_key.lower():\n",
    "                    try:\n",
    "                        kernel = f[top_key][\"conv1\"][\"kernel:0\"]\n",
    "                        shape = kernel.shape\n",
    "                        if len(shape) == 4:\n",
    "                            _, _, in_c, out_c = shape\n",
    "                            input_channels = in_c\n",
    "                            conv1_found = True\n",
    "                            print(f\"‚úÖ Found conv1: input channels = {in_c}, output channels = {out_c}\")\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                # Check backbone\n",
    "                if \"res5c_branch2a\" in top_key or \"res4b22_branch2a\" in top_key:\n",
    "                    backbone_type = \"resnet101\"\n",
    "                elif \"res5a_branch2a\" in top_key or \"res4f_branch2a\" in top_key:\n",
    "                    backbone_type = \"resnet50\"\n",
    "\n",
    "            # Summary\n",
    "            if not conv1_found:\n",
    "                print(\"‚ùå conv1/kernel:0 not found. Possibly excluded during save or replaced.\")\n",
    "            if backbone_type:\n",
    "                print(f\"‚úÖ Detected backbone: {backbone_type}\")\n",
    "            else:\n",
    "                print(\"‚ùì Could not confidently determine backbone type. Possibly custom or partial save.\")\n",
    "\n",
    "            return input_channels, backbone_type\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading HDF5 file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "h5_path = \"/Users/evanchan19/Desktop/COMP9517/project/logs/usa_rgb20250730T2338/mask_rcnn_usa_rgb_0011.h5\"\n",
    "inspect_maskrcnn_weights(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea97bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image\n",
      "zero_padding2d_3\n",
      "conv1\n",
      "bn_conv1\n",
      "activation_149\n",
      "max_pooling2d_3\n",
      "res2a_branch2a\n",
      "bn2a_branch2a\n",
      "activation_150\n",
      "res2a_branch2b\n",
      "bn2a_branch2b\n",
      "activation_151\n",
      "res2a_branch2c\n",
      "res2a_branch1\n",
      "bn2a_branch2c\n",
      "bn2a_branch1\n",
      "add_67\n",
      "res2a_out\n",
      "res2b_branch2a\n",
      "bn2b_branch2a\n",
      "activation_152\n",
      "res2b_branch2b\n",
      "bn2b_branch2b\n",
      "activation_153\n",
      "res2b_branch2c\n",
      "bn2b_branch2c\n",
      "add_68\n",
      "res2b_out\n",
      "res2c_branch2a\n",
      "bn2c_branch2a\n",
      "activation_154\n",
      "res2c_branch2b\n",
      "bn2c_branch2b\n",
      "activation_155\n",
      "res2c_branch2c\n",
      "bn2c_branch2c\n",
      "add_69\n",
      "res2c_out\n",
      "res3a_branch2a\n",
      "bn3a_branch2a\n",
      "activation_156\n",
      "res3a_branch2b\n",
      "bn3a_branch2b\n",
      "activation_157\n",
      "res3a_branch2c\n",
      "res3a_branch1\n",
      "bn3a_branch2c\n",
      "bn3a_branch1\n",
      "add_70\n",
      "res3a_out\n",
      "res3b_branch2a\n",
      "bn3b_branch2a\n",
      "activation_158\n",
      "res3b_branch2b\n",
      "bn3b_branch2b\n",
      "activation_159\n",
      "res3b_branch2c\n",
      "bn3b_branch2c\n",
      "add_71\n",
      "res3b_out\n",
      "res3c_branch2a\n",
      "bn3c_branch2a\n",
      "activation_160\n",
      "res3c_branch2b\n",
      "bn3c_branch2b\n",
      "activation_161\n",
      "res3c_branch2c\n",
      "bn3c_branch2c\n",
      "add_72\n",
      "res3c_out\n",
      "res3d_branch2a\n",
      "bn3d_branch2a\n",
      "activation_162\n",
      "res3d_branch2b\n",
      "bn3d_branch2b\n",
      "activation_163\n",
      "res3d_branch2c\n",
      "bn3d_branch2c\n",
      "add_73\n",
      "res3d_out\n",
      "res4a_branch2a\n",
      "bn4a_branch2a\n",
      "activation_164\n",
      "res4a_branch2b\n",
      "bn4a_branch2b\n",
      "activation_165\n",
      "res4a_branch2c\n",
      "res4a_branch1\n",
      "bn4a_branch2c\n",
      "bn4a_branch1\n",
      "add_74\n",
      "res4a_out\n",
      "res4b_branch2a\n",
      "bn4b_branch2a\n",
      "activation_166\n",
      "res4b_branch2b\n",
      "bn4b_branch2b\n",
      "activation_167\n",
      "res4b_branch2c\n",
      "bn4b_branch2c\n",
      "add_75\n",
      "res4b_out\n",
      "res4c_branch2a\n",
      "bn4c_branch2a\n",
      "activation_168\n",
      "res4c_branch2b\n",
      "bn4c_branch2b\n",
      "activation_169\n",
      "res4c_branch2c\n",
      "bn4c_branch2c\n",
      "add_76\n",
      "res4c_out\n",
      "res4d_branch2a\n",
      "bn4d_branch2a\n",
      "activation_170\n",
      "res4d_branch2b\n",
      "bn4d_branch2b\n",
      "activation_171\n",
      "res4d_branch2c\n",
      "bn4d_branch2c\n",
      "add_77\n",
      "res4d_out\n",
      "res4e_branch2a\n",
      "bn4e_branch2a\n",
      "activation_172\n",
      "res4e_branch2b\n",
      "bn4e_branch2b\n",
      "activation_173\n",
      "res4e_branch2c\n",
      "bn4e_branch2c\n",
      "add_78\n",
      "res4e_out\n",
      "res4f_branch2a\n",
      "bn4f_branch2a\n",
      "activation_174\n",
      "res4f_branch2b\n",
      "bn4f_branch2b\n",
      "activation_175\n",
      "res4f_branch2c\n",
      "bn4f_branch2c\n",
      "add_79\n",
      "res4f_out\n",
      "res4g_branch2a\n",
      "bn4g_branch2a\n",
      "activation_176\n",
      "res4g_branch2b\n",
      "bn4g_branch2b\n",
      "activation_177\n",
      "res4g_branch2c\n",
      "bn4g_branch2c\n",
      "add_80\n",
      "res4g_out\n",
      "res4h_branch2a\n",
      "bn4h_branch2a\n",
      "activation_178\n",
      "res4h_branch2b\n",
      "bn4h_branch2b\n",
      "activation_179\n",
      "res4h_branch2c\n",
      "bn4h_branch2c\n",
      "add_81\n",
      "res4h_out\n",
      "res4i_branch2a\n",
      "bn4i_branch2a\n",
      "activation_180\n",
      "res4i_branch2b\n",
      "bn4i_branch2b\n",
      "activation_181\n",
      "res4i_branch2c\n",
      "bn4i_branch2c\n",
      "add_82\n",
      "res4i_out\n",
      "res4j_branch2a\n",
      "bn4j_branch2a\n",
      "activation_182\n",
      "res4j_branch2b\n",
      "bn4j_branch2b\n",
      "activation_183\n",
      "res4j_branch2c\n",
      "bn4j_branch2c\n",
      "add_83\n",
      "res4j_out\n",
      "res4k_branch2a\n",
      "bn4k_branch2a\n",
      "activation_184\n",
      "res4k_branch2b\n",
      "bn4k_branch2b\n",
      "activation_185\n",
      "res4k_branch2c\n",
      "bn4k_branch2c\n",
      "add_84\n",
      "res4k_out\n",
      "res4l_branch2a\n",
      "bn4l_branch2a\n",
      "activation_186\n",
      "res4l_branch2b\n",
      "bn4l_branch2b\n",
      "activation_187\n",
      "res4l_branch2c\n",
      "bn4l_branch2c\n",
      "add_85\n",
      "res4l_out\n",
      "res4m_branch2a\n",
      "bn4m_branch2a\n",
      "activation_188\n",
      "res4m_branch2b\n",
      "bn4m_branch2b\n",
      "activation_189\n",
      "res4m_branch2c\n",
      "bn4m_branch2c\n",
      "add_86\n",
      "res4m_out\n",
      "res4n_branch2a\n",
      "bn4n_branch2a\n",
      "activation_190\n",
      "res4n_branch2b\n",
      "bn4n_branch2b\n",
      "activation_191\n",
      "res4n_branch2c\n",
      "bn4n_branch2c\n",
      "add_87\n",
      "res4n_out\n",
      "res4o_branch2a\n",
      "bn4o_branch2a\n",
      "activation_192\n",
      "res4o_branch2b\n",
      "bn4o_branch2b\n",
      "activation_193\n",
      "res4o_branch2c\n",
      "bn4o_branch2c\n",
      "add_88\n",
      "res4o_out\n",
      "res4p_branch2a\n",
      "bn4p_branch2a\n",
      "activation_194\n",
      "res4p_branch2b\n",
      "bn4p_branch2b\n",
      "activation_195\n",
      "res4p_branch2c\n",
      "bn4p_branch2c\n",
      "add_89\n",
      "res4p_out\n",
      "res4q_branch2a\n",
      "bn4q_branch2a\n",
      "activation_196\n",
      "res4q_branch2b\n",
      "bn4q_branch2b\n",
      "activation_197\n",
      "res4q_branch2c\n",
      "bn4q_branch2c\n",
      "add_90\n",
      "res4q_out\n",
      "res4r_branch2a\n",
      "bn4r_branch2a\n",
      "activation_198\n",
      "res4r_branch2b\n",
      "bn4r_branch2b\n",
      "activation_199\n",
      "res4r_branch2c\n",
      "bn4r_branch2c\n",
      "add_91\n",
      "res4r_out\n",
      "res4s_branch2a\n",
      "bn4s_branch2a\n",
      "activation_200\n",
      "res4s_branch2b\n",
      "bn4s_branch2b\n",
      "activation_201\n",
      "res4s_branch2c\n",
      "bn4s_branch2c\n",
      "add_92\n",
      "res4s_out\n",
      "res4t_branch2a\n",
      "bn4t_branch2a\n",
      "activation_202\n",
      "res4t_branch2b\n",
      "bn4t_branch2b\n",
      "activation_203\n",
      "res4t_branch2c\n",
      "bn4t_branch2c\n",
      "add_93\n",
      "res4t_out\n",
      "res4u_branch2a\n",
      "bn4u_branch2a\n",
      "activation_204\n",
      "res4u_branch2b\n",
      "bn4u_branch2b\n",
      "activation_205\n",
      "res4u_branch2c\n",
      "bn4u_branch2c\n",
      "add_94\n",
      "res4u_out\n",
      "res4v_branch2a\n",
      "bn4v_branch2a\n",
      "activation_206\n",
      "res4v_branch2b\n",
      "bn4v_branch2b\n",
      "activation_207\n",
      "res4v_branch2c\n",
      "bn4v_branch2c\n",
      "add_95\n",
      "res4v_out\n",
      "res4w_branch2a\n",
      "bn4w_branch2a\n",
      "activation_208\n",
      "res4w_branch2b\n",
      "bn4w_branch2b\n",
      "activation_209\n",
      "res4w_branch2c\n",
      "bn4w_branch2c\n",
      "add_96\n",
      "res4w_out\n",
      "res5a_branch2a\n",
      "bn5a_branch2a\n",
      "activation_210\n",
      "res5a_branch2b\n",
      "bn5a_branch2b\n",
      "activation_211\n",
      "res5a_branch2c\n",
      "res5a_branch1\n",
      "bn5a_branch2c\n",
      "bn5a_branch1\n",
      "add_97\n",
      "res5a_out\n",
      "res5b_branch2a\n",
      "bn5b_branch2a\n",
      "activation_212\n",
      "res5b_branch2b\n",
      "bn5b_branch2b\n",
      "activation_213\n",
      "res5b_branch2c\n",
      "bn5b_branch2c\n",
      "add_98\n",
      "res5b_out\n",
      "res5c_branch2a\n",
      "bn5c_branch2a\n",
      "activation_214\n",
      "res5c_branch2b\n",
      "bn5c_branch2b\n",
      "activation_215\n",
      "res5c_branch2c\n",
      "bn5c_branch2c\n",
      "add_99\n",
      "res5c_out\n",
      "fpn_c5p5\n",
      "fpn_p5upsampled\n",
      "fpn_c4p4\n",
      "fpn_p4add\n",
      "fpn_p4upsampled\n",
      "fpn_c3p3\n",
      "fpn_p3add\n",
      "fpn_p3upsampled\n",
      "fpn_c2p2\n",
      "fpn_p2add\n",
      "fpn_p5\n",
      "fpn_p2\n",
      "fpn_p3\n",
      "fpn_p4\n",
      "fpn_p6\n",
      "rpn_model\n",
      "rpn_class\n",
      "rpn_bbox\n",
      "input_anchors\n",
      "ROI\n",
      "input_image_meta\n",
      "roi_align_classifier\n",
      "mrcnn_class_conv1\n",
      "mrcnn_class_bn1\n",
      "activation_216\n",
      "mrcnn_class_conv2\n",
      "mrcnn_class_bn2\n",
      "activation_217\n",
      "pool_squeeze\n",
      "mrcnn_class_logits\n",
      "mrcnn_bbox_fc\n",
      "mrcnn_class\n",
      "mrcnn_bbox\n",
      "mrcnn_detection\n",
      "lambda_9\n",
      "roi_align_mask\n",
      "mrcnn_mask_conv1\n",
      "mrcnn_mask_bn1\n",
      "activation_219\n",
      "mrcnn_mask_conv2\n",
      "mrcnn_mask_bn2\n",
      "activation_220\n",
      "mrcnn_mask_conv3\n",
      "mrcnn_mask_bn3\n",
      "activation_221\n",
      "mrcnn_mask_conv4\n",
      "mrcnn_mask_bn4\n",
      "activation_222\n",
      "mrcnn_mask_deconv\n",
      "mrcnn_mask\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/evanchan19/Desktop/COMP9517/project/model/usa_rgb_nrg_resnet101/mask_rcnn_usa_rgb_0015.h5\"\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "import numpy as np\n",
    "\n",
    "class InferenceConfig(Config):\n",
    "    NAME = \"usa_rgb\"\n",
    "    NUM_CLASSES = 1 + 1  # Background + dead tree\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.1\n",
    "    IMAGE_CHANNEL_COUNT = 4\n",
    "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9, 114.5])\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Step 0: ÂàõÂª∫ inference model\n",
    "inference_model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=\"./logs\")\n",
    "inference_model.load_weights(path, by_name=True)\n",
    "\n",
    "for layer in inference_model.keras_model.layers:\n",
    "    print(layer.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcnn_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
